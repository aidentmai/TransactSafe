{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0c694c0-2b8c-4768-ba5a-e0099d36de5e",
   "metadata": {},
   "source": [
    "Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b359862-4908-44f4-83a6-9bffb22c3593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from geopy.distance import geodesic\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0df250c3-9f57-4a36-bbfd-f0fb0111ca51",
   "metadata": {},
   "source": [
    "Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92f5fcff-7120-4928-8eb3-30e46e1be4db",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Data Collection\n",
    "# CSV From Kaggle by Priyam Choksi\n",
    "df = pd.read_csv('credit_card_transactions.csv')\n",
    "\n",
    "# Feature engineering\n",
    "df['transaction_time'] = pd.to_datetime(df['trans_date_trans_time'])\n",
    "df['trans_hour'] = df['transaction_time'].dt.hour\n",
    "df['trans_day'] = df['transaction_time'].dt.weekday\n",
    "df['trans_year'] = df['transaction_time'].dt.year\n",
    "df['amt_ratio'] = df['amt'] / df.groupby('cc_num')['amt'].transform('mean')\n",
    "df['daily_transaction_count'] = df.groupby(['cc_num', 'trans_day'])['trans_num'].transform('count')\n",
    "\n",
    "# Drop unnecessary features\n",
    "df = df.drop(columns=['Unnamed: 0', 'trans_date_trans_time', 'transaction_time', 'trans_num', 'first', 'last',\n",
    "                      'gender', 'street', 'zip', 'city_pop', 'job', 'dob', 'unix_time', 'merch_zipcode'])\n",
    "\n",
    "# Function to get user distance from merchant\n",
    "def calc_distance(row):\n",
    "    return geodesic((row['lat'], row['long']), (row['merch_lat'], row['merch_long'])).miles\n",
    "\n",
    "df['user_location_distance'] = df.apply(calc_distance, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65e00298-5f98-476e-96f8-6c8971861e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cc_num</th>\n",
       "      <th>merchant</th>\n",
       "      <th>category</th>\n",
       "      <th>amt</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>lat</th>\n",
       "      <th>long</th>\n",
       "      <th>merch_lat</th>\n",
       "      <th>merch_long</th>\n",
       "      <th>is_fraud</th>\n",
       "      <th>trans_hour</th>\n",
       "      <th>trans_day</th>\n",
       "      <th>trans_year</th>\n",
       "      <th>amt_ratio</th>\n",
       "      <th>daily_transaction_count</th>\n",
       "      <th>user_location_distance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2703186189652095</td>\n",
       "      <td>fraud_Rippin, Kub and Mann</td>\n",
       "      <td>misc_net</td>\n",
       "      <td>4.97</td>\n",
       "      <td>Moravian Falls</td>\n",
       "      <td>NC</td>\n",
       "      <td>36.0788</td>\n",
       "      <td>-81.1781</td>\n",
       "      <td>36.011293</td>\n",
       "      <td>-82.048315</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.056869</td>\n",
       "      <td>250</td>\n",
       "      <td>48.947783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>630423337322</td>\n",
       "      <td>fraud_Heller, Gutmann and Zieme</td>\n",
       "      <td>grocery_pos</td>\n",
       "      <td>107.23</td>\n",
       "      <td>Orient</td>\n",
       "      <td>WA</td>\n",
       "      <td>48.8878</td>\n",
       "      <td>-118.2105</td>\n",
       "      <td>49.159047</td>\n",
       "      <td>-118.186462</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>1.987606</td>\n",
       "      <td>405</td>\n",
       "      <td>18.775736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38859492057661</td>\n",
       "      <td>fraud_Lind-Buckridge</td>\n",
       "      <td>entertainment</td>\n",
       "      <td>220.11</td>\n",
       "      <td>Malad City</td>\n",
       "      <td>ID</td>\n",
       "      <td>42.1808</td>\n",
       "      <td>-112.2620</td>\n",
       "      <td>43.150704</td>\n",
       "      <td>-112.154481</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>3.341580</td>\n",
       "      <td>69</td>\n",
       "      <td>67.172035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3534093764340240</td>\n",
       "      <td>fraud_Kutch, Hermiston and Farrell</td>\n",
       "      <td>gas_transport</td>\n",
       "      <td>45.00</td>\n",
       "      <td>Boulder</td>\n",
       "      <td>MT</td>\n",
       "      <td>46.2306</td>\n",
       "      <td>-112.1138</td>\n",
       "      <td>47.034331</td>\n",
       "      <td>-112.561071</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.618330</td>\n",
       "      <td>51</td>\n",
       "      <td>59.455974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>375534208663984</td>\n",
       "      <td>fraud_Keeling-Crist</td>\n",
       "      <td>misc_pos</td>\n",
       "      <td>41.96</td>\n",
       "      <td>Doe Hill</td>\n",
       "      <td>VA</td>\n",
       "      <td>38.4207</td>\n",
       "      <td>-79.4629</td>\n",
       "      <td>38.674999</td>\n",
       "      <td>-78.632459</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.440858</td>\n",
       "      <td>255</td>\n",
       "      <td>48.282030</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             cc_num                            merchant       category  \\\n",
       "0  2703186189652095          fraud_Rippin, Kub and Mann       misc_net   \n",
       "1      630423337322     fraud_Heller, Gutmann and Zieme    grocery_pos   \n",
       "2    38859492057661                fraud_Lind-Buckridge  entertainment   \n",
       "3  3534093764340240  fraud_Kutch, Hermiston and Farrell  gas_transport   \n",
       "4   375534208663984                 fraud_Keeling-Crist       misc_pos   \n",
       "\n",
       "      amt            city state      lat      long  merch_lat  merch_long  \\\n",
       "0    4.97  Moravian Falls    NC  36.0788  -81.1781  36.011293  -82.048315   \n",
       "1  107.23          Orient    WA  48.8878 -118.2105  49.159047 -118.186462   \n",
       "2  220.11      Malad City    ID  42.1808 -112.2620  43.150704 -112.154481   \n",
       "3   45.00         Boulder    MT  46.2306 -112.1138  47.034331 -112.561071   \n",
       "4   41.96        Doe Hill    VA  38.4207  -79.4629  38.674999  -78.632459   \n",
       "\n",
       "   is_fraud  trans_hour  trans_day  trans_year  amt_ratio  \\\n",
       "0         0           0          1        2019   0.056869   \n",
       "1         0           0          1        2019   1.987606   \n",
       "2         0           0          1        2019   3.341580   \n",
       "3         0           0          1        2019   0.618330   \n",
       "4         0           0          1        2019   0.440858   \n",
       "\n",
       "   daily_transaction_count  user_location_distance  \n",
       "0                      250               48.947783  \n",
       "1                      405               18.775736  \n",
       "2                       69               67.172035  \n",
       "3                       51               59.455974  \n",
       "4                      255               48.282030  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319d7e8c-6950-4f38-aaef-a0f1df661c80",
   "metadata": {},
   "source": [
    "Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d8ae5a18-34b2-493e-b8fb-30ee5715675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into training, validation, and test sets (70%, 15%, 15%)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = df.drop(columns=['is_fraud'])\n",
    "y = df['is_fraud']\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)  # 70% train, 30% temp\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)  # Split temp into 15% val and 15% test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d0c3b1-6e23-4d3e-a433-da28ae1e81b8",
   "metadata": {},
   "source": [
    "Label Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "724a530d-3685-4ff7-a389-6e1c8d513863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "# Label Encoding\n",
    "categorical_columns = ['merchant', 'category', 'city', 'state']\n",
    "label_encoded = {}\n",
    "for col in categorical_columns:\n",
    "    le = LabelEncoder()\n",
    "    X_train[col] = le.fit_transform(X_train[col])\n",
    "    X_val[col] = le.transform(X_val[col])\n",
    "    X_test[col] = le.transform(X_test[col])\n",
    "    label_encoded[col] = le"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e16660e-8f43-4a45-86f2-e9da2920ec4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method NDFrame.head of         merchant  category  city  state\n",
      "992821       571        11   869     17\n",
      "833489       462        12   697     50\n",
      "517107       687        11   347     15\n",
      "166051        52         8   259     45\n",
      "473161       490         6   268     25\n",
      "...          ...       ...   ...    ...\n",
      "110268       590         2   886     48\n",
      "259178       191         9   345      6\n",
      "131932       680         6   413     32\n",
      "671155       409        12   318     23\n",
      "121958        11        10    26     40\n",
      "\n",
      "[907672 rows x 4 columns]>\n"
     ]
    }
   ],
   "source": [
    "print(X_train[categorical_columns].head)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93daff30-91b6-41f3-8ca8-66bc5fab649d",
   "metadata": {},
   "source": [
    "Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "220d62e0-71dc-4b9c-83b3-1c49fec8417f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report, accuracy_score, precision_score, recall_score, roc_auc_score, roc_curve\n",
    "rf_model = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions on the validation set\n",
    "rf_y_val_pred = rf_model.predict(X_val)\n",
    "# Get predicted probabilities for the positive class (Fraud)\n",
    "rf_y_val_pred_proba = rf_model.predict_proba(X_val)[:, 1]  \n",
    "\n",
    "# Evaluate the model\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_val, rf_y_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, rf_y_val_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_val, rf_y_val_pred))\n",
    "\n",
    "# Calculate Precision and Recall\n",
    "precision = precision_score(y_val, rf_y_val_pred)\n",
    "recall = recall_score(y_val, rf_y_val_pred)\n",
    "print(f\"\\nPrecision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "\n",
    "# Calculate AUC-ROC\n",
    "roc_auc = roc_auc_score(y_val, rf_y_val_pred_proba)\n",
    "print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, rf_y_val_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, label=f'AUC = {roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c234241a-877c-4b35-8d77-455f0e93abd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the test set\n",
    "y_test_pred = rf_model.predict(X_test)\n",
    "y_test_pred_proba = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "print(\"Test Set Evaluation:\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_test, y_test_pred))\n",
    "print(\"\\nAccuracy Score:\")\n",
    "print(accuracy_score(y_test, y_test_pred))\n",
    "\n",
    "# Calculate Precision, Recall, and AUC-ROC for the test set\n",
    "test_precision = precision_score(y_test, y_test_pred)\n",
    "test_recall = recall_score(y_test, y_test_pred)\n",
    "test_roc_auc = roc_auc_score(y_test, y_test_pred_proba)\n",
    "\n",
    "print(f\"\\nTest Precision: {test_precision:.4f}\")\n",
    "print(f\"Test Recall: {test_recall:.4f}\")\n",
    "print(f\"Test AUC-ROC: {test_roc_auc:.4f}\")\n",
    "\n",
    "# Plot ROC Curve\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, y_test_pred_proba)\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test AUC = {test_roc_auc:.4f}')\n",
    "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve - Test Set')\n",
    "plt.legend(loc='lower right')\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7359c02e-149b-4a22-b709-36230e4bdb67",
   "metadata": {},
   "source": [
    "Feedforward Neural Network Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64b9001-849f-4e55-b808-acf4665f6236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardization\n",
    "scaler = StandardScaler()\n",
    "numerical_features = ['cc_num', 'amt', 'lat', 'long', 'merch_lat', 'merch_long', 'trans_hour', 'trans_day', 'trans_year', 'amt_ratio', 'daily_transaction_count', 'user_location_distance']\n",
    "X_train_numerical = scaler.fit_transform(X_train[numerical_features])\n",
    "X_val_numerical = scaler.transform(X_val[numerical_features])\n",
    "X_test_numerical = scaler.transform(X_test[numerical_features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f85319a-b7fc-481e-94f3-9666791889b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train_numerical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3076637-eb49-4e1b-a17b-cf7af085545a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(history):\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "    ax1.plot(history.history['loss'], label='loss')\n",
    "    ax1.plot(history.history['val_loss'], label='val_loss')\n",
    "    ax1.set_xlabel('Epoch')\n",
    "    ax1.set_ylabel('Binary crossentropy')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True)\n",
    "\n",
    "    ax2.plot(history.history['accuracy'], label='accuracy')\n",
    "    ax2.plot(history.history['val_accuracy'], label='val_accuracy')\n",
    "    ax2.set_xlabel('Epoch')\n",
    "    ax2.set_ylabel('Accuracy')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True)\n",
    "\n",
    "    plt.subplots_adjust(wspace=0.5)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0538f1d7-6111-4ce1-9ece-4a3692a01dae",
   "metadata": {},
   "source": [
    "Training FNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df69a89-1312-4994-8aec-d151a6689c23",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten, Concatenate\n",
    "from sklearn.metrics import precision_score, recall_score, roc_auc_score, roc_curve\n",
    "\n",
    "# Define Embedding Dimensions\n",
    "embedding_dim = {\n",
    "    'merchant': 200,\n",
    "    'category': 7,\n",
    "    'city': 200,\n",
    "    'state': 25\n",
    "}\n",
    "\n",
    "# Create Inputs and Embeddings for Each Categorical Feature\n",
    "merchant_input = Input(shape=(1,), name='merchant')\n",
    "merchant_embedding = Embedding(input_dim=len(label_encoded['merchant'].classes_), output_dim=embedding_dim['merchant'])(merchant_input)\n",
    "merchant_embedding = Flatten()(merchant_embedding)\n",
    "\n",
    "category_input = Input(shape=(1,), name='category')\n",
    "category_embedding = Embedding(input_dim=len(label_encoded['category'].classes_), output_dim=embedding_dim['category'])(category_input)\n",
    "category_embedding = Flatten()(category_embedding)\n",
    "\n",
    "city_input = Input(shape=(1,), name='city')\n",
    "city_embedding = Embedding(input_dim=len(label_encoded['city'].classes_), output_dim=embedding_dim['city'])(city_input)\n",
    "city_embedding = Flatten()(city_embedding)\n",
    "\n",
    "state_input = Input(shape=(1,), name='state')\n",
    "state_embedding = Embedding(input_dim=len(label_encoded['state'].classes_), output_dim=embedding_dim['state'])(state_input)\n",
    "state_embedding = Flatten()(state_embedding)\n",
    "\n",
    "numerical_input = Input(shape=(len(numerical_features),), name='numerical_features')\n",
    "\n",
    "# Concatenate embeddings and numerical inputs\n",
    "concat_embed = Concatenate()([merchant_embedding, category_embedding, city_embedding, state_embedding])\n",
    "\n",
    "concat_layer = Concatenate()([concat_embed, numerical_input])\n",
    "\n",
    "# Define FNN structure\n",
    "x = Dense(32, activation='relu')(concat_layer)\n",
    "x = Dense(32, activation='relu')(x)\n",
    "output = Dense(1, activation='sigmoid')(x)\n",
    "\n",
    "fnn_model = Model(\n",
    "    inputs={\n",
    "        'merchant': merchant_input,\n",
    "        'category': category_input,\n",
    "        'city': city_input,\n",
    "        'state': state_input,\n",
    "        'numerical_features': numerical_input\n",
    "    },\n",
    "    outputs=output\n",
    ")\n",
    "fnn_model.compile(optimizer=tf.keras.optimizers.Adam(0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Prepare Training and Validation Data\n",
    "train_inputs = {\n",
    "    'merchant': np.array(X_train['merchant']),\n",
    "    'category': np.array(X_train['category']),\n",
    "    'city': np.array(X_train['city']),\n",
    "    'state': np.array(X_train['state']),\n",
    "    'numerical_features': np.array(X_train_numerical)\n",
    "}\n",
    "\n",
    "val_inputs = {\n",
    "    'merchant': np.array(X_val['merchant']),\n",
    "    'category': np.array(X_val['category']),\n",
    "    'city': np.array(X_val['city']),\n",
    "    'state': np.array(X_val['state']),\n",
    "    'numerical_features': np.array(X_val_numerical)\n",
    "}\n",
    "\n",
    "# Train model\n",
    "history = fnn_model.fit(\n",
    "    train_inputs, \n",
    "    np.array(y_train), \n",
    "    epochs=25, \n",
    "    batch_size=32, \n",
    "    validation_data=(val_inputs, np.array(y_val)), \n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a87727-0486-4b67-9c43-6322f6148706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Precision, Recall, and AUC-ROC\n",
    "fnn_y_pred_proba = fnn_model.predict(val_inputs).flatten()\n",
    "threshold = 0.5\n",
    "fnn_y_pred = (fnn_y_pred_proba >= threshold).astype(int)\n",
    "\n",
    "fnn_precision = precision_score(y_val, fnn_y_pred)\n",
    "fnn_recall = recall_score(y_val, fnn_y_pred)\n",
    "fnn_auc = roc_auc_score(y_val, fnn_y_pred_proba)\n",
    "\n",
    "print(\"Precision:\", fnn_precision)\n",
    "print(\"Recall:\", fnn_recall)\n",
    "print(\"AUC-ROC Score:\", fnn_auc)\n",
    "\n",
    "# Plotting the ROC Curve\n",
    "fpr, tpr, thresholds = roc_curve(y_val, fnn_y_pred_proba)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(fpr, tpr, color='blue', label=f'ROC Curve (AUC = {fnn_auc:.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='gray', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate (Recall)')\n",
    "plt.title('ROC Curve')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b528e9c-ee6a-4531-bff3-3ea3885f3e02",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e26e54-5ac6-49b4-bcd4-a572953538da",
   "metadata": {},
   "source": [
    "Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e783c1e8-57ef-45e0-b04f-c1545e5cc13d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Combine RF and FNN predictions\n",
    "combined_val_predictions = np.column_stack((rf_y_val_pred_proba, fnn_y_pred_proba))\n",
    "\n",
    "# Define LR model\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(combined_val_predictions, y_val)\n",
    "\n",
    "# Evaluate LR model\n",
    "lr_val_pred_prob = lr_model.predict_proba(combined_val_predictions)[:, 1]\n",
    "lr_val_pred = (lr_val_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Evaluate metrics\n",
    "lr_val_precision = precision_score(y_val, lr_val_pred)\n",
    "lr_val_recall = recall_score(y_val, lr_val_pred)\n",
    "lr_val_auc = roc_auc_score(y_val, lr_val_pred_prob)\n",
    "lr_val_accuracy = accuracy_score(y_val, lr_val_pred)\n",
    "\n",
    "print(\"Validation Precision:\", lr_val_precision)\n",
    "print(\"Validation Recall:\", lr_val_recall)\n",
    "print(\"Validation AUC-ROC:\", lr_val_auc)\n",
    "print(\"Validation Accuracy:\", lr_val_accuracy)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(confusion_matrix(y_val, lr_val_pred))\n",
    "print(\"\\nClassification Report:\")\n",
    "print(classification_report(y_val, lr_val_pred))\n",
    "\n",
    "# Get predictions from both models on the test set and evaluate the Logistic Regression model\n",
    "# Random Forest test predictions\n",
    "rf_test_pred_prob = rf_model.predict_proba(X_test)[:, 1]\n",
    "\n",
    "# FNN test predictions\n",
    "fnn_test_pred_prob = fnn_model.predict({\n",
    "    'merchant': np.array(X_test['merchant']),\n",
    "    'category': np.array(X_test['category']),\n",
    "    'city': np.array(X_test['city']),\n",
    "    'state': np.array(X_test['state']),\n",
    "    'numerical_features': np.array(X_test_numerical)\n",
    "}).flatten()\n",
    "\n",
    "# Combine test predictions for Logistic Regression\n",
    "combined_test_predictions = np.column_stack((rf_test_pred_prob, fnn_test_pred_prob))\n",
    "\n",
    "# Evaluate on test set using Logistic Regression\n",
    "lr_test_pred_prob = lr_model.predict_proba(combined_test_predictions)[:, 1]\n",
    "lr_test_pred = (lr_test_pred_prob >= 0.5).astype(int)\n",
    "\n",
    "# Test set evaluation metrics\n",
    "lr_test_precision = precision_score(y_test, lr_test_pred)\n",
    "lr_test_recall = recall_score(y_test, lr_test_pred)\n",
    "lr_test_auc = roc_auc_score(y_test, lr_test_pred_prob)\n",
    "lr_test_accuracy = accuracy_score(y_test, lr_test_pred)\n",
    "\n",
    "print(\"\\nTest Precision:\", lr_test_precision)\n",
    "print(\"Test Recall:\", lr_test_recall)\n",
    "print(\"Test AUC-ROC:\", lr_test_auc)\n",
    "print(\"Test Accuracy:\", lr_test_accuracy)\n",
    "print(\"\\nConfusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, lr_test_pred))\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, lr_test_pred))\n",
    "\n",
    "# Plot ROC Curve for Logistic Regression on Validation Set\n",
    "fpr_val, tpr_val, thresholds_val = roc_curve(y_val, lr_val_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_val, tpr_val, label=f'Validation AUC = {lr_val_auc:.4f}', color='blue')\n",
    "plt.plot([0, 1], [0, 1], 'k--', label=\"Random Classifier\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Validation Set (Logistic Regression)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()\n",
    "\n",
    "# Plot ROC Curve for Logistic Regression on Test Set\n",
    "fpr_test, tpr_test, thresholds_test = roc_curve(y_test, lr_test_pred_prob)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(fpr_test, tpr_test, label=f'Test AUC = {lr_test_auc:.4f}', color='green')\n",
    "plt.plot([0, 1], [0, 1], 'k--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curve - Test Set (Logistic Regression)')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4dc1372-d791-4322-ba0e-d6d689d1efd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "# Save Random Forest\n",
    "joblib.dump(rf_model, 'random_forest_model.pkl')\n",
    "print(\"Random Forest model saved.\")\n",
    "\n",
    "# Save Feedforward Neural Network\n",
    "fnn_model.save('fnn_model.keras')\n",
    "print(\"FNN model saved.\")\n",
    "\n",
    "# Save Logistic Regression\n",
    "joblib.dump(lr_model, 'logistic_regression_model.pkl')\n",
    "print(\"Logistic Regression model saved.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
